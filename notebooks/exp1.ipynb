{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82790c87",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7e0ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:23.227865Z",
     "iopub.status.busy": "2025-04-28T11:55:23.227865Z",
     "iopub.status.idle": "2025-04-28T11:55:44.261829Z",
     "shell.execute_reply": "2025-04-28T11:55:44.258811Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "import re \n",
    "import string\n",
    "import nltk \n",
    "import string \n",
    "from nltk. corpus import stopwords \n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14af8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:44.278591Z",
     "iopub.status.busy": "2025-04-28T11:55:44.276592Z",
     "iopub.status.idle": "2025-04-28T11:55:45.490181Z",
     "shell.execute_reply": "2025-04-28T11:55:45.485449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ec5189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:45.500183Z",
     "iopub.status.busy": "2025-04-28T11:55:45.498184Z",
     "iopub.status.idle": "2025-04-28T11:55:45.520120Z",
     "shell.execute_reply": "2025-04-28T11:55:45.518745Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['tweet_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfeb9f",
   "metadata": {},
   "source": [
    "#### data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d06632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:45.520120Z",
     "iopub.status.busy": "2025-04-28T11:55:45.520120Z",
     "iopub.status.idle": "2025-04-28T11:55:45.556127Z",
     "shell.execute_reply": "2025-04-28T11:55:45.552128Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = df[df['sentiment'].isin(['happiness','sadness'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1270c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:45.566784Z",
     "iopub.status.busy": "2025-04-28T11:55:45.565127Z",
     "iopub.status.idle": "2025-04-28T11:55:45.663473Z",
     "shell.execute_reply": "2025-04-28T11:55:45.660928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iampr\\AppData\\Local\\Temp\\ipykernel_16276\\1062716855.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sentiment'] = final_df['sentiment'].replace(\n"
     ]
    }
   ],
   "source": [
    "final_df['sentiment'] = final_df['sentiment'].replace(\n",
    "    {\n",
    "        'happiness': 1,\n",
    "        'sadness': 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf4dd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:45.670066Z",
     "iopub.status.busy": "2025-04-28T11:55:45.670066Z",
     "iopub.status.idle": "2025-04-28T11:55:45.693263Z",
     "shell.execute_reply": "2025-04-28T11:55:45.690816Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(final_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a602fe8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:45.703426Z",
     "iopub.status.busy": "2025-04-28T11:55:45.702426Z",
     "iopub.status.idle": "2025-04-28T11:55:46.254234Z",
     "shell.execute_reply": "2025-04-28T11:55:46.254234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\iampr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\iampr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f557b6d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:46.269913Z",
     "iopub.status.busy": "2025-04-28T11:55:46.264256Z",
     "iopub.status.idle": "2025-04-28T11:55:46.337863Z",
     "shell.execute_reply": "2025-04-28T11:55:46.336378Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(y) for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words (text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    Text = [i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(Text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    text = \"\".join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    text = text.split()\n",
    "    text = [y.lower() for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    # Remove punctuation using regex and string.punctuation\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    \n",
    "    #remove extra whitespace\n",
    "    text = re.sub('\\s+',' ', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def removing_urls(text):\n",
    "    url_pattern = re.compile(r'https://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_small_sentences(df):\n",
    "    for i in range(len(df)):\n",
    "        if len(df.text.iloc[i].split()) < 3:\n",
    "            df.text.iloc[1] = np.nan\n",
    "            \n",
    "            \n",
    "def normalize_text(df):\n",
    "    df.content = df.content.apply(lambda content : lower_case(content))\n",
    "    df.content = df.content.apply(lambda content : remove_stop_words(content))\n",
    "    df.content = df.content.apply(lambda content : removing_numbers(content))\n",
    "    df.content = df.content.apply(lambda content : removing_punctuations(content))\n",
    "    df.content = df.content.apply(lambda content : removing_urls(content))\n",
    "    df.content = df.content.apply(lambda content : lemmatization(content))    \n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_sentence(sentence):\n",
    "    sentence = lower_case(sentence)\n",
    "    sentence = remove_stop_words(sentence)\n",
    "    sentence = removing_numbers(sentence)\n",
    "    sentence = removing_punctuations(sentence)\n",
    "    sentence = removing_urls(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6d7c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:55:46.337863Z",
     "iopub.status.busy": "2025-04-28T11:55:46.337863Z",
     "iopub.status.idle": "2025-04-28T11:56:54.551310Z",
     "shell.execute_reply": "2025-04-28T11:56:54.551310Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = normalize_text(train_data)\n",
    "test_data = normalize_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d153c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:56:54.568701Z",
     "iopub.status.busy": "2025-04-28T11:56:54.555687Z",
     "iopub.status.idle": "2025-04-28T11:56:54.587362Z",
     "shell.execute_reply": "2025-04-28T11:56:54.587362Z"
    }
   },
   "outputs": [],
   "source": [
    "#extract x-train, x-test, y-train, y-test\n",
    "X_train = train_data['content'].values\n",
    "y_train = train_data['sentiment'].values\n",
    "\n",
    "X_test = test_data['content'].values\n",
    "y_test = test_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdb7e0",
   "metadata": {},
   "source": [
    "#### text vectorization - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8a8dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:56:54.634239Z",
     "iopub.status.busy": "2025-04-28T11:56:54.634239Z",
     "iopub.status.idle": "2025-04-28T11:56:55.804818Z",
     "shell.execute_reply": "2025-04-28T11:56:55.804818Z"
    }
   },
   "outputs": [],
   "source": [
    "#bow vectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "x_train_bow = vectorizer.fit_transform(X_train)\n",
    "x_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2170f3",
   "metadata": {},
   "source": [
    "#### MLFlow experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e195263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:56:55.804818Z",
     "iopub.status.busy": "2025-04-28T11:56:55.804818Z",
     "iopub.status.idle": "2025-04-28T11:57:07.070858Z",
     "shell.execute_reply": "2025-04-28T11:57:07.070858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as iamprashantjain\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as iamprashantjain\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"iamprashantjain/mlops-mini-project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"iamprashantjain/mlops-mini-project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository iamprashantjain/mlops-mini-project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository iamprashantjain/mlops-mini-project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/7f52cd073c034a88bca79863caa6a1e7', creation_time=1745838305051, experiment_id='1', last_update_time=1745838305051, lifecycle_stage='active', name='Decision Tree Baseline', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='iamprashantjain', repo_name='mlops-mini-project', mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/iamprashantjain/mlops-mini-project.mlflow\")\n",
    "mlflow.set_experiment('Decision Tree Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807a0ae",
   "metadata": {},
   "source": [
    "#### applying decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd77064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:57:07.086931Z",
     "iopub.status.busy": "2025-04-28T11:57:07.086931Z",
     "iopub.status.idle": "2025-04-28T12:32:45.380528Z",
     "shell.execute_reply": "2025-04-28T12:32:45.380528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/28 17:29:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7180722891566265\n",
      "precision:  0.701310861423221\n",
      "recall:  0.7379310344827587\n",
      "f1_score:  0.7191550648103696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/28 18:02:44 INFO mlflow.tracking._tracking_service.client: üèÉ View run puzzled-seal-254 at: https://dagshub.com/iamprashantjain/mlops-mini-project.mlflow/#/experiments/1/runs/8223fc964f1b428bae1e37cd0612b45e.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/28 18:02:44 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/iamprashantjain/mlops-mini-project.mlflow/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"vectorizer\", \"BOW\")\n",
    "    mlflow.log_param(\"num_features\", 1000)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "            \n",
    "    # Train model\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(x_train_bow, y_train)\n",
    "    mlflow.log_param(\"model\",\"Decision Tree\")\n",
    "    \n",
    "    #evaluation   \n",
    "    y_pred = dt.predict(x_test_bow)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics and params\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('precision', prec)\n",
    "    mlflow.log_metric('recall', rec)\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    " \n",
    "\n",
    "    #log model\n",
    "    mlflow.sklearn.log_model(dt, \"Decision_Tree_Model\")\n",
    "    \n",
    "    #log jupyter notebook\n",
    "    import os\n",
    "    notebook_path = \"exp1.ipynb\"\n",
    "    os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "    mlflow.log_artifact(notebook_path)\n",
    "    \n",
    "    \n",
    "    print(\"accuracy: \", accuracy)\n",
    "    print(\"precision: \", prec)\n",
    "    print(\"recall: \", rec)\n",
    "    print(\"f1_score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fd813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
